# See:
# - https://immich.app/docs/developer/setup
# - https://immich.app/docs/developer/troubleshooting

services:
  frigate-machine-learning:
    container_name: frigate_machine_learning
    image: frigate-machine-learning:latest
    # extends:
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - DEVICE=cuda # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # count: "all" # 1
              device_ids: ['0'] # must comment the above line if this line is uncommented.
              capabilities: [gpu]    
    ports:
      - 3003:3003
    volumes:
      - .:/usr/src/app
      - ./models/.cache:/cache
    env_file:
      - .env
    # depends_on:
    #   - database
    restart: unless-stopped


# volumes:
#   model-cache:
